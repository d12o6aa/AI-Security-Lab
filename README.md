#  AI Security & Red Teaming Lab

Welcome to my AI Security learning journey! This repository is a practical documentation of my path towards becoming an **AI Red Teamer**. I explore the intersection of Cybersecurity principles and Machine Learning vulnerabilities, with a focus on securing Large Language Models (LLMs).

##  About Me
* **Name:** Doaa Karem
* **Role:** Computer Science Student at Helwan University (Class of 2026)
* **GPA:** 2.93 (Cumulative up to 7th Semester)
* **Specialization:** AI Security & Adversarial ML
* **Current Focus:** Developing **ArabGuard** - A tool to protect LLMs against Prompt Injection attacks in Egyptian Arabic and Franco-Arabic.

---

##  AI Red Teaming Roadmap
I am following the [roadmap.sh](https://roadmap.sh/ai-red-teaming) for AI Red Teaming to build a strong foundation in:

### 1. Foundational Knowledge
- [ ] **AI/ML Fundamentals:** Supervised, Unsupervised, Reinforcement Learning, and Neural Networks.
- [ ] **Cybersecurity Principles:** CIA Triad (Confidentiality, Integrity, Availability).
- [ ] **Threat Modeling:** Risk Management and Vulnerability Assessment.

### 2. Model Vulnerabilities & Attacks
- [ ] **Prompt Hacking:** Jailbreaking, Safety Filter Bypasses, and Prompt Injection (Direct/Indirect).
- [ ] **System Security:** Data Poisoning, Model Inversion, and Extraction.
- [ ] **Infrastructure:** API Protection and Authentication Security.

---

##  Experiments & Research
In this lab, I implement concepts from key research papers and practical testing:

###  [Data-Poisoning-Research](./Data-Poisoning-Research)
[cite_start]Implementation of concepts from the **Nisos Research Report (August 2024)**[cite: 4]:
* [cite_start]**Attack Types:** Mislabeling, Data Injection, and Backdoor Attacks[cite: 55].
* [cite_start]**Mitigation Logic:** Data validation, Sanitization, and Adversarial training[cite: 20].
* [cite_start]**Real-world Cases:** Analysis of Gmail spam filter and Microsoft Tay attacks[cite: 18].

###  [ArabGuard-Development](./ArabGuard)
My graduation project workspace:
* **Dataset:** Egyptian Arabic & Franco-Arabic Prompt Injection examples.
* **Logic:** Detection and filtering of adversarial prompts in local dialects.

---

##  Tools & Technologies
* **Language:** Python 
* **Environment:** Linux / MySQL 
* **Frameworks:** Scikit-learn, TensorFlow/PyTorch (Coming soon)
* **Testing:** Adversarial Robustness Toolbox (ART)

---

##  Study Resources
* [cite_start]**Nisos Research:** "Building Trustworthy AI: Contending with Data Poisoning"[cite: 3].
* [cite_start]**Red Teaming Roadmap:** roadmap.sh/ai-red-teaming[cite: 479].
* [cite_start]**Guidance:** Learn Prompting[cite: 472].

---
*“Vigilance is the price of security in the age of AI.”*